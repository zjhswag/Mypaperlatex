% Luhn (1958) - TF-IDF 雏形
@article{luhn1958automatic,
  title={The automatic creation of literature abstracts},
  author={Luhn, Hans Peter},
  journal={IBM Journal of research and development},
  volume={2},
  number={2},
  pages={159--165},
  year={1958},
  publisher={IBM}
}

@article{erkan2004lexrank,
  title={Lexrank: Graph-based lexical centrality as salience in text summarization},
  author={Erkan, G{\"u}nes and Radev, Dragomir R},
  journal={Journal of artificial intelligence research},
  volume={22},
  pages={457--479},
  year={2004}
}

@inproceedings{wan2007manifold,
  title={Manifold-Ranking Based Topic-Focused Multi-Document Summarization.},
  author={Wan, Xiaojun and Yang, Jianwu and Xiao, Jianguo and others},
  booktitle={IJCAI},
  volume={7},
  pages={2903--2908},
  year={2007}
}
@inproceedings{wan2010towards,
  title={Towards a unified approach to simultaneous single-document and multi-document summarizations},
  author={Wan, Xiaojun},
  booktitle={Proceedings of the 23rd international conference on computational linguistics (Coling 2010)},
  pages={1137--1145},
  year={2010}
}
@inproceedings{kupiec1995trainable,
  title={A trainable document summarizer},
  author={Kupiec, Julian and Pedersen, Jan and Chen, Francine},
  booktitle={Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={68--73},
  year={1995}
}
@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@inproceedings{zhu2018msmo,
  title={MSMO: Multimodal summarization with multimodal output},
  author={Zhu, Junnan and Li, Haoran and Liu, Tianshang and Zhou, Yu and Zhang, Jiajun and Zong, Chengqing},
  booktitle={Proceedings of the 2018 conference on empirical methods in natural language processing},
  pages={4154--4164},
  year={2018}
}

@article{zhang2024benchmarking,
  title={Benchmarking large language models for news summarization},
  author={Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={39--57},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@inproceedings{osborne2002using,
  title={Using maximum entropy for sentence extraction},
  author={Osborne, Miles},
  booktitle={Proceedings of the ACL-02 workshop on automatic summarization},
  pages={1--8},
  year={2002}
}

@inproceedings{conroy2001text,
  title={Text summarization via hidden markov models},
  author={Conroy, John M and O'leary, Dianne P},
  booktitle={Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={406--407},
  year={2001}
}

@inproceedings{shen2007document,
  title={Document summarization using conditional random fields.},
  author={Shen, Dou and Sun, Jian-Tao and Li, Hua and Yang, Qiang and Chen, Zheng},
  booktitle={IJCAI},
  volume={7},
  pages={2862--2867},
  year={2007}
}

@article{cheng2016neural,
  title={Neural summarization by extracting sentences and words},
  author={Cheng, Jianpeng and Lapata, Mirella},
  journal={arXiv preprint arXiv:1603.07252},
  year={2016}
}
@inproceedings{nallapati2017summarunner,
  title={Summarunner: A recurrent neural network based sequence model for extractive summarization of documents},
  author={Nallapati, Ramesh and Zhai, Feifei and Zhou, Bowen},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{narayan2018ranking,
  title={Ranking sentences for extractive summarization with reinforcement learning},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1802.08636},
  year={2018}
}

@article{hu2015lcsts,
  title={Lcsts: A large scale chinese short text summarization dataset},
  author={Hu, Baotian and Chen, Qingcai and Zhu, Fangze},
  journal={arXiv preprint arXiv:1506.05865},
  year={2015}
}
@article{liu2019text,
  title={Text summarization with pretrained encoders},
  author={Liu, Yang and Lapata, Mirella},
  journal={arXiv preprint arXiv:1908.08345},
  year={2019}
}
@inproceedings{wang2020heterogeneous,
  title={Heterogeneous graph neural networks for extractive document summarization},
  author={Wang, Danqing and Liu, Pengfei and Zheng, Yining and Qiu, Xipeng and Huang, Xuan-Jing},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={6209--6219},
  year={2020}
}

@article{li2017deep,
  title={Deep recurrent generative decoder for abstractive text summarization},
  author={Li, Piji and Lam, Wai and Bing, Lidong and Wang, Zihao},
  journal={arXiv preprint arXiv:1708.00625},
  year={2017}
}

@inproceedings{zhong2020extractive,
  title={Extractive summarization as text matching},
  author={Zhong, Ming and Liu, Pengfei and Chen, Yiran and Wang, Danqing and Qiu, Xipeng and Huang, Xuan-Jing},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={6197--6208},
  year={2020}
}

@article{zhang2023extractive,
  title={Extractive summarization via chatgpt for faithful summary generation},
  author={Zhang, Haopeng and Liu, Xiao and Zhang, Jiawei},
  journal={arXiv preprint arXiv:2304.04193},
  year={2023}
}
@article{wang2023element,
  title={Element-aware summarization with large language models: Expert-aligned evaluation and chain-of-thought method},
  author={Wang, Yiming and Zhang, Zhuosheng and Wang, Rui},
  journal={arXiv preprint arXiv:2305.13412},
  year={2023}
}

@article{liu2023g,
  title={G-eval: NLG evaluation using gpt-4 with better human alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={arXiv preprint arXiv:2303.16634},
  year={2023}
}

@article{rush2015neural,
  title={A neural attention model for abstractive sentence summarization},
  author={Rush, Alexander M and Chopra, Sumit and Weston, Jason},
  journal={arXiv preprint arXiv:1509.00685},
  year={2015}
}

@inproceedings{chopra2016abstractive,
  title={Abstractive sentence summarization with attentive recurrent neural networks},
  author={Chopra, Sumit and Auli, Michael and Rush, Alexander M},
  booktitle={Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies},
  pages={93--98},
  year={2016}
}

@article{yu2019review,
  title={A review of recurrent neural networks: LSTM cells and network architectures},
  author={Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
  journal={Neural computation},
  volume={31},
  number={7},
  pages={1235--1270},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{edmundson1969new,
  title={New methods in automatic extracting},
  author={Edmundson, Harold P},
  journal={Journal of the ACM (JACM)},
  volume={16},
  number={2},
  pages={264--285},
  year={1969},
  publisher={ACM New York, NY, USA}
}

@inproceedings{mihalcea2004textrank,
  title={Textrank: Bringing order into text},
  author={Mihalcea, Rada and Tarau, Paul},
  booktitle={Proceedings of the 2004 conference on empirical methods in natural language processing},
  pages={404--411},
  year={2004}
}
@article{lead3,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% 4. BertSumExt

% 2. PGN+Coverage (这个之前给过，这里确保key一致)
@inproceedings{see2017get,
  title={Get To The Point: Summarization with Pointer-Generator Networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1073--1083},
  year={2017}
}
% 1. Seq2Seq+Attention
@inproceedings{nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and Dos Santos, Cicero and Gul{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Xiang, Bing},
  booktitle={Proceedings of the 20th SIGNLL conference on computational natural language learning},
  pages={280--290},
  year={2016}
}

@article{hui2024qwen2,
  title={Qwen2. 5-coder technical report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}

@inproceedings{zhang2020pegasus,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle={International conference on machine learning},
  pages={11328--11339},
  year={2020},
  organization={PMLR}
}

@article{song2019mass,
  title={Mass: Masked sequence to sequence pre-training for language generation},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1905.02450},
  year={2019}
}

@article{qi2020prophetnet,
  title={Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training},
  author={Qi, Weizhen and Yan, Yu and Gong, Yeyun and Liu, Dayiheng and Duan, Nan and Chen, Jiusheng and Zhang, Ruofei and Zhou, Ming},
  journal={arXiv preprint arXiv:2001.04063},
  year={2020}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{lewis2020bart,
  title={BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={7871--7880},
  year={2020}
}

@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{grootendorst2022bertopic,
  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  author={Grootendorst, Maarten},
  journal={arXiv preprint arXiv:2203.05794},
  year={2022}
}

@misc{hockett1953mathematical,
  title={The mathematical theory of communication},
  author={Hockett, Charles F},
  year={1953},
  publisher={JSTOR}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@inproceedings{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering.},
  author={Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick SH and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle={EMNLP (1)},
  pages={6769--6781},
  year={2020}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46534--46594},
  year={2023}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}

@inproceedings{campello2013density,
  title={Density-based clustering based on hierarchical density estimates},
  author={Campello, Ricardo JGB and Moulavi, Davoud and Sander, J{\"o}rg},
  booktitle={Pacific-Asia conference on knowledge discovery and data mining},
  pages={160--172},
  year={2013},
  organization={Springer}
}

@book{bird2009natural,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={" O'Reilly Media, Inc."}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}

@article{srivastava2015highway,
  title={Highway networks},
  author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1505.00387},
  year={2015}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}

@article{cohan2018discourse,
  title={A discourse-aware attention model for abstractive summarization of long documents},
  author={Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},
  journal={arXiv preprint arXiv:1804.05685},
  year={2018}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{schick2022peer,
  title={Peer: A collaborative language model},
  author={Schick, Timo and Dwivedi-Yu, Jane and Jiang, Zhengbao and Petroni, Fabio and Lewis, Patrick and Izacard, Gautier and You, Qingfei and Nalmpantis, Christoforos and Grave, Edouard and Riedel, Sebastian},
  journal={arXiv preprint arXiv:2208.11663},
  year={2022}
}

@article{li2023camel,
  title={Camel: Communicative agents for" mind" exploration of large scale language model society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  year={2023},
  publisher={ArXiv}
}

@article{gehrmann2018bottom,
  title={Bottom-up abstractive summarization},
  author={Gehrmann, Sebastian and Deng, Yuntian and Rush, Alexander M},
  journal={arXiv preprint arXiv:1808.10792},
  year={2018}
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}

@article{vilnis2014word,
  title={Word representations via gaussian embedding},
  author={Vilnis, Luke and McCallum, Andrew},
  journal={arXiv preprint arXiv:1412.6623},
  year={2014}
}

@article{alemi2016deep,
  title={Deep variational information bottleneck},
  author={Alemi, Alexander A and Fischer, Ian and Dillon, Joshua V and Murphy, Kevin},
  journal={arXiv preprint arXiv:1612.00410},
  year={2016}
}